{
  
    
        "post0": {
            "title": "USR",
            "content": "Wstęp . Celem projektu jest porównanie skuteczności wybranych pięciu technik ML na zbiorze danych składającym się z 303 obserwacji. Jakość wyestymowanych modeli zostanie oceniona na zbiorze uczącym oraz testowym, a następnie najlepszy model zostanie zinterpretowany. Ze względu na istotną w tym projekcie interpretację wyników podjęto decyzję o wybraniu danych medycznych. Dane pacjentów pochodzą z bazy danych szpitala w Cleveland. Zestaw zawiera 14 zmiennych, w tym binarną zmianą target, która przyjmuje wartość 1, gdy u pacjenta występuje choroba serca lub 0, gdy nie występuje. . Dane . Wykorzystany w projekcie zbiór danych Heart został opracowany na podstawie zestawu dostępnego pod adresem: https://archive.ics.uci.edu/ml/datasets/Heart+Disease. Zawiera wspomnianą wcześniej zmienną objaśnianą target oraz 13 zmiennych objaśniających: . age - wiek pacjenta | sex - zmienna binarna oznaczająca płeć: 1 - mężczyzna, 0-kobieta | cp rodzaj bólu w klatce piersiowej związany z chorobą dusznicą bolesną w angielskiej terminologii medycznej podzielona na cztery kategorie: 0: nie występuje | 1: typical angina | 2: atypical angina | 3: non-anginal pain | 4: asymptomatic | . | trestbps - ciśnienie tętnicze w mm Hg po przyjęciu do szpitala | chol stężenie cholesterolu w surowicy krwi wyrażone w mg/dl | fbs zmienna binarna przyjmuje wartość 1 jeżeli poziom cukru we krwi (badany na czczo) był większy niż 120 mg/dl, jeżeli nie to wartość 0 | restecg zmienna jakościowa charakteryzująca wyniki elektrokardiograficzne w stanie spoczynku 0: normalny | 1: nieprawidłowość fali ST-T1 | 2: wykazujący prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa | . | thalach maksymalne tętno, które miał pacjent | exang zmienna binarna przyjmując wartość 1 gdy wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym, w przeciwnym przypadku zmienna przyjmuje wartość 0 | oldpeak wskazuje obniżenie odcinka ST2 wywołane wysiłkiem fizycznym | slope określenie szczytowej wartości nachylenia odcinka ST zmierzony podczas elektrokardiograficznego testu wysiłkowego 0: nie występuje | 1: wznoszący się | 2: płaskie | 3: opadające (downsloping) | . | ca liczba zabarwionych głównych naczyń (0-3) w wyniku badania fluoroskopii | thal zmienna jakościowa: 0: nie występuje | 1: 3 = normal | 2: 6 = fixed defect | 3: 7 = reversable defe | . | Dane nie zawierają braków oraz wartości odstających. Poniżej zaprezentowano 6 pierwszych obserwacji pochodzących ze zbioru danych. . ## age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target ## 1 63 1 3 145 233 1 0 150 0 2.3 0 0 1 1 ## 2 37 1 2 130 250 0 1 187 0 3.5 0 0 2 1 ## 3 41 0 1 130 204 0 0 172 0 1.4 2 0 2 1 ## 4 56 1 1 120 236 0 1 178 0 0.8 2 0 2 1 ## 5 57 0 0 120 354 0 1 163 1 0.6 2 0 2 1 ## 6 57 1 0 140 192 0 1 148 0 0.4 1 0 1 1 . Wizualizacja wybranych zmiennych . Zmienna objaśniana . . W danych ok. 54% pacjentów zostało zdiagnozowanych pozytywnie to znaczy wykryto u nich chorobę serca (wartość 1), pozostałe 46% to przypadki, w których nie stwierdzono takiej diagnozy (wartość 0). . Zmienna objaśniana według płci . . Analizując wartości zmiennej objaśnianej target z podziałem na płeć można stwierdzić, że niezależnie od płci więcej przypadków w zbiorze stanowiły osoby u których zdiagnozowano chorobę serca. W próbie dominowali mężczyźni, którzy stanowili 68% rozważanych przypadków. . Rozkład wieku pacjentów . . Obserwując rozkład wieku badanych pacjentów, można ocenić, że są to osoby głównie w wieku średnim i emerytalnym. . Wiek i płeć pacjentów względem zmiennej objaśnianej . . Analiza wieku z podziałem na płeć wskazuje, że średnio kobiety były starsze w obu grupach zdiagnozowanych: pozytywnie jak i negatywnie. Trochę mniejsza różnica wieku między kobietami i mężczyznami wystąpiła wśród osób u których stwierdzono chorobę serca. . Podstawowe statystki opisowe . summary(heart) . ## age sex cp trestbps chol fbs ## Min. :29.00 0: 96 0:143 Min. : 94.0 Min. :126.0 0:258 ## 1st Qu.:47.50 1:207 1: 50 1st Qu.:120.0 1st Qu.:211.0 1: 45 ## Median :55.00 2: 87 Median :130.0 Median :240.0 ## Mean :54.37 3: 23 Mean :131.6 Mean :246.3 ## 3rd Qu.:61.00 3rd Qu.:140.0 3rd Qu.:274.5 ## Max. :77.00 Max. :200.0 Max. :564.0 ## restecg thalach exang oldpeak slope ca thal target ## 0:147 Min. : 71.0 0:204 Min. :0.00 0: 21 0:175 0: 2 0:138 ## 1:152 1st Qu.:133.5 1: 99 1st Qu.:0.00 1:140 1: 65 1: 18 1:165 ## 2: 4 Median :153.0 Median :0.80 2:142 2: 38 2:166 ## Mean :149.6 Mean :1.04 3: 20 3:117 ## 3rd Qu.:166.0 3rd Qu.:1.60 4: 5 ## Max. :202.0 Max. :6.20 . W zbiorze danych znajduje się kilka zmiennych jakościowych, które w języku R zostały zamienione na factory. Dla zmiennych ilościowych można odczytać, że średnia wieku pacjenta to 54 lata, najmłodsza przyjęta osoba miał 29 lat, a najstarsza 77. Średnie ciśnienie tętnicze (trestbps) wynosiło 131, czyli przekraczało normę medyczną dla osoby dorosłej wynoszącą 120 mm Hg. Średnia wartość stężenia cholesterolu w surowicy krwi również przekracza normę dla mężczyzny 125-200 mg/d. Maksymalne tętno pacjenta wynosiło 202, gdy norma medyczna to ok. 90 uderzeń na minutę, jednak jest to zmienna wieloma różnymi czynnikami, więc raczej należy ją rozpatrywać indywidualnie dla każdego pacjenta śledząc jego historię. oldpeak to wskazanie obniżenia odcinka ST, którego wartość mieści się w przedziale 0 do 6,20. . Podzial zbioru . Zbiór danych podzielony został na zbiór uczący oraz testowy w stosunku 70/30. W celu umożliwienia interpretacji wyników i ich powtarzalność ziarno generatora ustawiono na liczbę 3012. . set.seed(3012) rand &lt;- sample(303, 212, replace=F) uczacy&lt;- heart[rand,] testowy&lt;- heart[-rand,] . Modele . Wyestymowane zostaną wybrane modele ML, które zostaną zbudowane na zbiorze uczącym, proces ten będzie połączony z tuningowaniem modeli, czyli dobieraniu możliwie najlepszych wartości hierparametrów. Kryterium wyboru będzie miara dokładności. Do trenowania modelu wykorzystana zostanie metoda cross-validation z k=10. Ze względów technicznych dotyczących budowania modeli w pakiecie caret wartości zmiennej objaśnianej target zostały zmienione z 0 na ‘no’ oraz z 1 na ‘yes’. . Regresja logistyczna . Model regresji logistycznej nie zawiera, żadnych parametrów, które można byłoby wykorzystać do “strojenia”. Model zbudowany został dla 12 zmiennych objaśniających z pominięciem zmiennej thal. Zmienna ta została odrzucona ze względu na współliniowość. . ## ## Call: ## NULL ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.66454 -0.28812 0.09274 0.41134 2.87943 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.710365 3.613080 1.027 0.304456 ## age 0.035669 0.033207 1.074 0.282769 ## sex1 -3.141392 0.722460 -4.348 1.37e-05 *** ## cp1 1.066653 0.766703 1.391 0.164158 ## cp2 1.837301 0.625662 2.937 0.003319 ** ## cp3 1.473897 0.870804 1.693 0.090537 . ## trestbps -0.023982 0.014919 -1.608 0.107941 ## chol -0.007602 0.005515 -1.378 0.168054 ## fbs1 0.543764 0.674136 0.807 0.419891 ## restecg1 0.487174 0.520184 0.937 0.348994 ## restecg2 -1.312916 2.924249 -0.449 0.653449 ## thalach 0.021459 0.014562 1.474 0.140575 ## exang1 -1.104601 0.577601 -1.912 0.055826 . ## oldpeak -0.511579 0.291908 -1.753 0.079682 . ## slope1 -1.374487 1.047819 -1.312 0.189601 ## slope2 0.126517 1.167314 0.108 0.913692 ## ca1 -2.071210 0.681284 -3.040 0.002365 ** ## ca2 -3.531743 0.973100 -3.629 0.000284 *** ## ca3 -2.060758 0.939645 -2.193 0.028298 * ## ca4 0.580439 1.766650 0.329 0.742493 ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 292.00 on 211 degrees of freedom ## Residual deviance: 120.71 on 192 degrees of freedom ## AIC: 160.71 ## ## Number of Fisher Scoring iterations: 6 . Jako istotne na poziomie istotności równym 0.05 model wskazał zmienne: . sex1 czyli płeć, gdzie 1 oznaczało mężczyznę, | cp2 oznaczający 2 typ bólu klatki piersiowej w angielskiej terminologii nazywany atypical angina, | ca1,ca2, ca3 trzy z pięciu wartości wskazujących liczbę zabarwionych głównych naczyń w wyniku badania fluoroskopii, | zmienna exang1 przyjmująca wartość 1 w przypadkach w których wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym nieznacznie przekracza poziom istotności 0.056. | . Jakość modelu . Jakość modelu zbadana zostanie za pomocą macierzy pomyłek oraz krzywej ROC, czyli narzędzi służących do oceny jakości klasyfikatorów. Analogiczne kroki zostaną wykonane dla kolejnych modeli. . Zbiór uczący . ## Generalized Linear Model ## ## 212 samples ## 12 predictor ## 2 classes: &#39;no&#39;, &#39;yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 190, 192, 192, 190, 190, 190, ... ## Resampling results: ## ## Accuracy Kappa ## 0.8593939 0.7147427 . ## Cross-Validated (10 fold) Confusion Matrix ## ## (entries are percentual average cell counts across resamples) ## ## Reference ## Prediction no yes ## no 37.3 6.1 ## yes 8.0 48.6 ## ## Accuracy (average) : 0.8585 . . Na zbiorze uczącym dokładność modelu wyniosła ok. 85,9%. . Zbiór testowy . ## Confusion Matrix and Statistics ## ## Reference ## Prediction no yes ## no 31 8 ## yes 11 41 ## ## Accuracy : 0.7912 ## 95% CI : (0.6933, 0.8694) ## No Information Rate : 0.5385 ## P-Value [Acc &gt; NIR] : 4.723e-07 ## ## Kappa : 0.5778 ## ## Mcnemar&#39;s Test P-Value : 0.6464 ## ## Sensitivity : 0.8367 ## Specificity : 0.7381 ## Pos Pred Value : 0.7885 ## Neg Pred Value : 0.7949 ## Prevalence : 0.5385 ## Detection Rate : 0.4505 ## Detection Prevalence : 0.5714 ## Balanced Accuracy : 0.7874 ## ## &#39;Positive&#39; Class : yes ## . . W przypadku zbioru testowego dokładność była trochę mniejsza i wyniosła 79,1%. . K najbliższych sąsiadów (KNN) . Metoda K najbliższych sąsiadów ma tylko jeden hiperparametr k, który określa liczbę sąsiadów. Biorąc pod uwagę wielkość zbioru uczącego podjęto decyzję o sprawdzeniu wartości od 1 do 15. . ## k-Nearest Neighbors ## ## 212 samples ## 13 predictor ## 2 classes: &#39;no&#39;, &#39;yes&#39; ## ## Pre-processing: centered (22), scaled (22) ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 192, 191, 190, 191, 190, 191, ... ## Resampling results across tuning parameters: ## ## k Accuracy Kappa ## 1 0.7776840 0.5502807 ## 2 0.7826623 0.5570748 ## 3 0.8249134 0.6470095 ## 4 0.8405844 0.6749595 ## 5 0.8537662 0.7039078 ## 6 0.8449351 0.6863048 ## 7 0.8637879 0.7239010 ## 8 0.8342641 0.6650397 ## 9 0.8533333 0.7038954 ## 10 0.8635498 0.7228767 ## 11 0.8492424 0.6951588 ## 12 0.8492424 0.6953141 ## 13 0.8583117 0.7133712 ## 14 0.8444805 0.6844237 ## 15 0.8540043 0.7046377 ## ## Accuracy was used to select the optimal model using the largest value. ## The final value used for the model was k = 7. . Jako najlepszy wybrany został model w którym hiperparemetr k przyjął wartość 7. . Jakość modelu . Zbiór uczący . ## Cross-Validated (10 fold) Confusion Matrix ## ## (entries are percentual average cell counts across resamples) ## ## Reference ## Prediction no yes ## no 37.3 5.7 ## yes 8.0 49.1 ## ## Accuracy (average) : 0.8632 . . Zbiór testowy . ## Confusion Matrix and Statistics ## ## Reference ## Prediction no yes ## no 32 9 ## yes 10 40 ## ## Accuracy : 0.7912 ## 95% CI : (0.6933, 0.8694) ## No Information Rate : 0.5385 ## P-Value [Acc &gt; NIR] : 4.723e-07 ## ## Kappa : 0.5792 ## ## Mcnemar&#39;s Test P-Value : 1 ## ## Sensitivity : 0.8163 ## Specificity : 0.7619 ## Pos Pred Value : 0.8000 ## Neg Pred Value : 0.7805 ## Prevalence : 0.5385 ## Detection Rate : 0.4396 ## Detection Prevalence : 0.5495 ## Balanced Accuracy : 0.7891 ## ## &#39;Positive&#39; Class : yes ## . . Podsumowując dla modelu KNN dokładność na zbiorze uczącym wynosiła 86,3%, na zbiorze testowym była trochę niższa 79,1%. . SVM . Model Support Vector Machine (SVM) ma trzy hiperparametry dla każdego z nich sprawdzono 3 wartości. Na wykresie poniżej przedstawiono dokładność modeli przy różnych wartościach hiperparametrów. . . Analizując wyniki można stwierdzić, że najlepszy układ hiperparametrów tj. taki w którym dokładność modelu jest największa to degree = 1, scale = 0.06 and C = 0.1. . ## Support Vector Machines with Polynomial Kernel ## ## 212 samples ## 13 predictor ## 2 classes: &#39;no&#39;, &#39;yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 191, 190, 191, 192, 191, 191, ... ## Resampling results across tuning parameters: ## ## degree scale C Accuracy Kappa ## 1 0.01 0.10 0.8014069 0.6106969 ## 1 0.01 0.15 0.8109307 0.6279186 ## 1 0.01 0.20 0.8395455 0.6776615 ## 1 0.01 0.25 0.8443074 0.6870762 ## 1 0.06 0.10 0.8445455 0.6865250 ## 1 0.06 0.15 0.8302597 0.6574206 ## 1 0.06 0.20 0.8350216 0.6668447 ## 1 0.06 0.25 0.8443290 0.6861652 ## 1 0.10 0.10 0.8302597 0.6569918 ## 1 0.10 0.15 0.8490909 0.6949940 ## 1 0.10 0.20 0.8306926 0.6574938 ## 1 0.10 0.25 0.8493074 0.6960327 ## 2 0.01 0.10 0.8395455 0.6776615 ## 2 0.01 0.15 0.8443074 0.6870762 ## 2 0.01 0.20 0.8493074 0.6959381 ## 2 0.01 0.25 0.8445455 0.6865250 ## 2 0.06 0.10 0.8397835 0.6761758 ## 2 0.06 0.15 0.8397835 0.6761758 ## 2 0.06 0.20 0.8254762 0.6470406 ## 2 0.06 0.25 0.8304762 0.6574508 ## 2 0.10 0.10 0.8257143 0.6482034 ## 2 0.10 0.15 0.8211688 0.6391519 ## 2 0.10 0.20 0.8211688 0.6394218 ## 2 0.10 0.25 0.8164069 0.6290653 ## 3 0.01 0.10 0.8395455 0.6776615 ## 3 0.01 0.15 0.8445455 0.6871092 ## 3 0.01 0.20 0.8397835 0.6761024 ## 3 0.01 0.25 0.8352381 0.6669639 ## 3 0.06 0.10 0.8257143 0.6468919 ## 3 0.06 0.15 0.8209524 0.6371616 ## 3 0.06 0.20 0.8397835 0.6747770 ## 3 0.06 0.25 0.8302597 0.6559688 ## 3 0.10 0.10 0.8447835 0.6849516 ## 3 0.10 0.15 0.8309307 0.6579170 ## 3 0.10 0.20 0.8306926 0.6583416 ## 3 0.10 0.25 0.8213853 0.6390976 ## ## Accuracy was used to select the optimal model using the largest value. ## The final values used for the model were degree = 1, scale = 0.1 and C = 0.25. . Jakość modelu . Zbiór uczący . ## Cross-Validated (10 fold) Confusion Matrix ## ## (entries are percentual average cell counts across resamples) ## ## Reference ## Prediction no yes ## no 37.7 7.5 ## yes 7.5 47.2 ## ## Accuracy (average) : 0.8491 . . Zbiór testowy . ## Confusion Matrix and Statistics ## ## Reference ## Prediction no yes ## no 31 8 ## yes 11 41 ## ## Accuracy : 0.7912 ## 95% CI : (0.6933, 0.8694) ## No Information Rate : 0.5385 ## P-Value [Acc &gt; NIR] : 4.723e-07 ## ## Kappa : 0.5778 ## ## Mcnemar&#39;s Test P-Value : 0.6464 ## ## Sensitivity : 0.8367 ## Specificity : 0.7381 ## Pos Pred Value : 0.7885 ## Neg Pred Value : 0.7949 ## Prevalence : 0.5385 ## Detection Rate : 0.4505 ## Detection Prevalence : 0.5714 ## Balanced Accuracy : 0.7874 ## ## &#39;Positive&#39; Class : yes ## . . Dokładność modelu SVM na zbiorze uczącym to ok 84.9%, a na zbiorze testowym była dokładnie taka sama jak dla modelu KNN, czyli 79,1%. . Drzewo klasyfikacyjne . Drzewo decyzyjne wykorzystywane w problemach klasyfikacyjnych nazwane jest drzewem klasyfikacyjnym. Ta metoda, ma tylko jeden hiperparametr cp, który określa wielkość drzewa. Sprawdzono sześć wartości 0.001, 0.01, 0.05, 0.1, 0.5, 0.9. Dla najlepszego modelu przedstawiona zostanie wizualizacja drzewa klasyfikacyjnego. . ## CART ## ## 212 samples ## 13 predictor ## 2 classes: &#39;no&#39;, &#39;yes&#39; ## ## No pre-processing ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 191, 191, 192, 190, 190, 190, ... ## Resampling results across tuning parameters: ## ## cp Accuracy Kappa ## 0.001 0.7532251 0.5024319 ## 0.010 0.7532251 0.5024319 ## 0.050 0.7550000 0.5076560 ## 0.100 0.7695238 0.5355896 ## 0.500 0.5608658 0.0384000 ## 0.900 0.5472294 0.0000000 ## ## Accuracy was used to select the optimal model using the largest value. ## The final value used for the model was cp = 0.1. . . Jakość modelu . Zbiór uczący . ## Cross-Validated (10 fold) Confusion Matrix ## ## (entries are percentual average cell counts across resamples) ## ## Reference ## Prediction no yes ## no 34.0 11.8 ## yes 11.3 42.9 ## ## Accuracy (average) : 0.7689 . . Zbiór testowy . ## Confusion Matrix and Statistics ## ## Reference ## Prediction no yes ## no 30 10 ## yes 12 39 ## ## Accuracy : 0.7582 ## 95% CI : (0.6572, 0.8419) ## No Information Rate : 0.5385 ## P-Value [Acc &gt; NIR] : 1.259e-05 ## ## Kappa : 0.5119 ## ## Mcnemar&#39;s Test P-Value : 0.8312 ## ## Sensitivity : 0.7959 ## Specificity : 0.7143 ## Pos Pred Value : 0.7647 ## Neg Pred Value : 0.7500 ## Prevalence : 0.5385 ## Detection Rate : 0.4286 ## Detection Prevalence : 0.5604 ## Balanced Accuracy : 0.7551 ## ## &#39;Positive&#39; Class : yes ## . . Model drzewa klasyfikacyjnego na zbiorze uczącym osiągnął 76,9% dokładność, natomiast na zbiorze uczącym 75,8%. . Random Forest . Model Random Forest posiada trzy hiperparametry: mtry, splitrule (gini lub extratrees), min.node.size. W przypadku tego modelu do doboru wartości hiperparametrów wykorzystano parametr tuneLength=10 funkcji train(), który realizuje wybór parametrów w strategii Random Search. Wyniki tego poszukiwania zaprezentowano na wykresie. . . ## Random Forest ## ## 212 samples ## 13 predictor ## 2 classes: &#39;no&#39;, &#39;yes&#39; ## ## Pre-processing: centered (22), scaled (22) ## Resampling: Cross-Validated (10 fold) ## Summary of sample sizes: 192, 190, 191, 191, 191, 191, ... ## Resampling results across tuning parameters: ## ## mtry splitrule Accuracy Kappa ## 2 gini 0.8222294 0.6400503 ## 2 extratrees 0.8319913 0.6603155 ## 4 gini 0.7893290 0.5751768 ## 4 extratrees 0.8270130 0.6509168 ## 6 gini 0.7986364 0.5946163 ## 6 extratrees 0.8081602 0.6122585 ## 8 gini 0.7981818 0.5945051 ## 8 extratrees 0.8181602 0.6328588 ## 10 gini 0.7845671 0.5671843 ## 10 extratrees 0.8313420 0.6577469 ## 13 gini 0.7698268 0.5372009 ## 13 extratrees 0.8083983 0.6132109 ## 15 gini 0.7984199 0.5947808 ## 15 extratrees 0.8129437 0.6218473 ## 17 gini 0.7795887 0.5564938 ## 17 extratrees 0.8129437 0.6218473 ## 19 gini 0.7795887 0.5564938 ## 19 extratrees 0.8122727 0.6211723 ## 22 gini 0.7748268 0.5469927 ## 22 extratrees 0.8124892 0.6214471 ## ## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 1 ## Accuracy was used to select the optimal model using the largest value. ## The final values used for the model were mtry = 2, splitrule = extratrees ## and min.node.size = 1. . Hiperparametry modeli z największą wartością miary dokładności mtry = 2, splirtule = extratrees oraz min.node.size = 1. . Jakość modelu . Zbiór uczący . ## Cross-Validated (10 fold) Confusion Matrix ## ## (entries are percentual average cell counts across resamples) ## ## Reference ## Prediction no yes ## no 36.3 8.0 ## yes 9.0 46.7 ## ## Accuracy (average) : 0.8302 . . Zbiór testowy . ## Confusion Matrix and Statistics ## ## Reference ## Prediction no yes ## no 30 9 ## yes 12 40 ## ## Accuracy : 0.7692 ## 95% CI : (0.6691, 0.8511) ## No Information Rate : 0.5385 ## P-Value [Acc &gt; NIR] : 4.473e-06 ## ## Kappa : 0.5333 ## ## Mcnemar&#39;s Test P-Value : 0.6625 ## ## Sensitivity : 0.8163 ## Specificity : 0.7143 ## Pos Pred Value : 0.7692 ## Neg Pred Value : 0.7692 ## Prevalence : 0.5385 ## Detection Rate : 0.4396 ## Detection Prevalence : 0.5714 ## Balanced Accuracy : 0.7653 ## ## &#39;Positive&#39; Class : yes ## . . Model Random Forest z wybranymi wartościami hiperparametrów osiągnął 83% dokładności na zbiorze uczącym oraz 76,9% na zbiorze uczącym. . Wyniki i wybór modelu . Zestawienie miary dokładności miary dokładności dla zbioru uczącego: . model accuracy_train . regresja logistyczna | 0.859 | . KNN | 0.863 | . SVM | 0.849 | . drzewo | 0.769 | . Random Forest | 0.830 | . W przypadku zbioru testowego dodatkowo dodano miarę czułość (sensitivity), która wskazuje jaka część klasy pozytywnej jest pokryta pozytywnym przewidywaniem. . model accuracy_test sensivity_test . regresja logistyczna | 0.791 | 0.837 | . KNN | 0.791 | 0.816 | . SVM | 0.791 | 0.837 | . drzewo | 0.758 | 0.796 | . Random Forest | 0.769 | 0.816 | . Ponadto na jednym wykresie przedstawiono krzywe ROC dla wszystkich modeli. . . gdzie . M1 - model regresji liniowej | M2 - model KNN | M3 - model SVM | M4 - model drzewo klasyfikacyjne | M5 - model Random Forest | . Wnioski . Analizując otrzymane rezultaty można stwierdzić, że: . najgorszym modelem na zbiorze testowym oraz uczącym był model drzewa klasyfikacyjnego (dokładność 75,8%) | dokładność pozostałych 4 modeli na zbiorze uczącym przekroczyła 83% | najlepszy na zbiorze uczącym był model KNN 86.3% | trzy modele: regresja logistyczna, KNN, SVM uzyskały dokładnie taką samą dokładność 79,1% na zbiorze testowym | dwa modele: regresja logistyczna oraz SVM miały taką samą najwyższą czułość 83,7% dla zbioru testowego | dwa modele: KNN oraz Random Forest również miały taką samą czułość, która wynosiła 81.6% | krzywe ROC potwierdzają, że 4 modele były do siebie bardzo podobne, a jeden (drzewo klasyfikacyjne) odstawał, najbliżej idealnego modelu wydaje się być model KNN oznaczony kolorem zielonym, jednak różnice są bardzo małe | . Do interpretacji wybrano model KNN, ponieważ na to wskazuje porównanie krzywych ROC, najwyższa dokładność w zbiorze uczącym oraz w zbiorze testowym. . Interpretacja modelu . Profile PCP . Profile ceteris-paribus (PCP) oceniają wpływ wybranej zmiennej objaśniającej na zmiany predykcji modelu wywołane zmianami wartości zmiennej przy założeniu, że inne wartości pozostają stałe. Poniżej zaprezentowano profile stworzone na podstawie modelu KNN, rozważany są dwa przypadki: 1) 54 pacjent 2) 54 pacjentka . Profile PCP 54-letni pacjent zmienne ilościowe . . Interpretacja Wykres profilu PCP pozwala interpretować wyniki w odniesieniu do jednej konkretniej obserwacji tutaj dla 54-letniego mężczyzny. Zmienna ilościowe: . age gdyby pacjent był starszy znacznie wzrosłaby szansa, że zostanie zdiagnozowany pozytywnie, można przypuszczać, że jeżeli pacjent nie zadba o swoje zdrowie to niedługo (rok/dwa) otrzyma diagnozę z chorobą serca | chol wysokie stężenie cholesterolu w surowicy krwi bezpośrednio wiąże się z ryzykiem wystąpienia chorób serca, norma medyczna dla mężczyzn to przedział 125-200 mg/dl, pacjent nieznacznie przekracza normę, ale gdyby miał wyższe stężenie klasyfikowałby się jako pacjent z chorobą serca | oldpeak wskazuje obniżenie odcinka ST wywołane wysiłkiem fizycznym, przy wartości pomiędzy 3 i 4 u pacjenta zdiagnozowano by chorobę serca | thalach norma medyczna dla maksymalnego tętna wynosi 60-90 uderzeń/min, więc można zauważyć, że u badanego pacjenta norma dla dorosłego człowieka została przekroczona dwukrotnie | trestbps wysoka wartość ciśnienia tętniczego oznacza pozytywną diagnozą obecności choroby serca, wartość dla rozważanego pacjenta nieznacznie przekracza normę medyczną wynoszącą 120 mm Hg, gdyby wzrosła do ok. 130 zostałby zdiagnozowany jako pacjent z chorobą serca | . Profile PCP 54-letni pacjent zmienne jakościowe . . Interpretacja Wybrane zmienne jakościowe: . cp gdyby pacjent zgłaszał dowolny typ bólu klatki piersiowej związany z dusznicą bolesną (wartość 1 lub 2) zdiagnozowano by go pozytywnie, wartości 0 i 3 wykluczają obecność tej konkretniej choroby i zmniejszają prawdopodobieństwo wystąpienia choroby serca | exang gdyby u pacjenta wystąpiła wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym zakwalifikowano by go jako chorego na serce, | fbs jeżeli poziom cukru we krwi pacjenta był większy niż 120 mg/dl (wartość zmiennej 1) to byłby zdiagnozowany pozytywnie | restecg przy wartości 1 pacjent zostałby zdiagnozowany jako osoba chora na serce, zastanawiać może wartość 2, która według modelu miałby obniżać prawdopodobieństwo pozytywnej diagnozy, co oznacza jego defekt ponieważ wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa, a wiec bezpośrednio łączy się z chorobą serca | sex gdyby ten pacjent był kobietą zdiagnozowano by jako pacjenta z chorobą serca | . Profile PCP 54-letni pacjentka . . Interpretacja Rozważany przypadek 54-letniej kobiety wskazuje, że jej stan jest bardzo ciężki i zmiany wartości dla większości zmiennych zakładając stałość pozostałych nie wpłynęliby na zmianę diagnozy. Wyjątek stanowią: . oldpeak zmiana wartości obniżenia odcinka ST wywołane wysiłkiem fizycznym mogłaby zmniejszyć prawdopodobieństwo, ale dalej pozostałoby ono na dość wysokim poziomie, | restecg przy wartości 2 prawdopodobieństwo pozytywnej diagnozy pacjentki znacznie by się zmniejszyło, co jest kolejnym dowodem na niewłaściwie działanie modelu w kontekście tej zmiennej ponieważ wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estes, a więc bezpośrednio łączy się z chorobą serca | thal obniżenie tej zmiennej do wartości 1 oznaczałoby zmniejszenie prawdopodobieństwa, tutaj taka zasada działania modelu jest uzasadniona, ponieważ wartość 1 dla tej zmiennej oznacza stan normalny | cp wartość 3 dla pacjentki oznaczałaby obniżenie prawdopodobieństwa diagnozy choroby serca, ponieważ oznacza ból typu non-anginal pain, czyli ból nie związany z chorobą serca | . Profile PDP . Wykresy częściowej zależności (PDP) ich idea polega na uśrednieniu wartości wszystkich (poza jedną) zmiennych predykcyjnych i obserwacji zmiany w odpowiedzi Y. W odróżnieniu od profili PCP dotyczą całej próby, a nie pojedynczego przypadku. . . Interpretacja Zgodnie z przedstawionym wykresem profili PDP dla modelu KNN można stwierdzić, że: . age wiek w niewielki sposób wpływa na prawdopodobieństwo prognozy pozytywnej -chol wysoka wartość cholesterolu wiąże się z większą szansą na diagnozę choroby serca | wraz ze wzrostem wartości oldpeak spada prawdopodobieństwo wystąpienia choroby serca u pacjenta | im większa wartość thalach tym większe prawdopodobieństwo pozytywnej diagnozy | trwstbps ma raczej stały wpływ niezależnie od wartości w przedziale od ok. 100 do ok. 200 | . Wartości Shapley’a . Związane są z zagadnieniem znanym z teorii gier dotyczącym podziału nagrody między graczy, którzy mieli różny udział w wygranej. W ML wygrana to wartość predykcji, a graczami są zmienne, czyli atrybuty. Wartości dotyczą pojedynczych obserwacji i przedstawiają udział poszczególnych zmiennych w predykcji. Ponownie rozpatrzone zostaną przypadki 54-letniego pacjenta i pacjentki, które analizowano dla profili PCP. . 54-letni pacjent . . Wartości Shapley’a pozwalają ustalić, że dla badanego 54-letniego mężczyzny prawdopodobieństwo pozytywnej diagnozy zmniejszają dwie zmienne: . sex przyjmująca wartość 1, co oznacza, że fakt, że jest mężczyzną obniża prawdopodobieństwa diagnozy u niego choroby serca, | age zmienna wiek obniża szansę na stwierdzenie choroby serca u tego pacjenta o 10% Pozostałe zmienne zaprezentowane na wykresie zwiększają prawdopodobieństwo stwierdzenia choroby serca u tego pacjenta: | thal przyjmująca wartość 2 oznacza fixed defect, czyli stałą wadę i to ona w 10% wpływa na zwiększenie prawdopodobieństwa | ca dwa zabarwione główne naczynia w badaniu fluoroskopii to czynnik, który o 11% zwiększa szansę na pozytywną diagnozę | slope dodaje podobną wartość 7%, oznacza to, że nachylenie odcinka ST przyjmujące wartość 2 czyli ‘płaskie’ jest istotnym czynnikiem zwiększającym prawdopodobieństwa stwierdzenia choroby serca | . 54-letnia pacjentka . . Wykres otrzymany na podstawie wartości Shapley’a potwierdzają interpretację profilu PCP tej 54-letniej pacjentki, która jest “beznadziejnym przypadkiem”. W jej wynikach każda zmienna zwiększa szansę na pozytywną diagnozę. Największy wpływ 11% ma zmienna ca=0 związana z fluoroskopią. Podobnie jak w przypadku poprzedniego pacjenta zmienna thal=2 oznaczająca występowanie stałej wady zwiększa szanse pozytywnej diagnozy o 10%. Kolejne 7% dodają zmienne slope=2 oraz cp=0. . Analizując oba przypadki wartości dwojga pacjentów w tym samym wieku można zaobserwować znaczne podobieństwa, pomimo różnej diagnozy tj. różnego wyniku zmiennej objaśniającej dla każdego z nich. . Zakończenie . Cele projektu zostały zrealizowane, wyestymowano pięć modeli ML w tym dwa bazujące na drzewach decyzyjnych. Dokonano oceny jakości na podstawie miary dokładności, czułości oraz krzywych ROC. Wybrano najlepszy model i dokonano jego interpretacji przy wykorzystaniu Profili PCP, PDP oraz wartości Shapley’a. Spośród badanych modeli najlepszy dla analizowanego zbioru danych okazał się model KNN z 86% dokładnością na zbiorze uczącym oraz 79% na zbiorze uczącym. Przy okazji analizowania profili PCP i PDP odkryto prawdopodobną wadę modelu - zmienną restecg, która gdy przyjmuje wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa, tymczasem model uznawał tą wartość jako podwód do obniżenia prawdopodobieństwa występowanie choroby serca. W celu zbadania tego problemu należałby skonsultować się z ekspertem w tej dziedzinie lub znaleźć odpowiedź w literaturze. Intuicyjnie takie zachowanie modelu można uznać za błędne. Należałby podjąć próbę zbudowania nowego modelu bez tej zmiennej i przeprowadzenie analizy porównawczej wyników. . oryginalne wyjaśnienie medyczne dotyczące tej zmiennej (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV) &#8617; . | odcinek ST – w terminologii medycznej określenie fragmentu zapisu elektrokardiograficznego odpowiadającego początkowej fazie repolaryzacji mięśnia komór serca. &#8617; . |",
            "url": "https://naliem.github.io/portfolio/2021/07/20/USwR.html",
            "relUrl": "/2021/07/20/USwR.html",
            "date": " • Jul 20, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://naliem.github.io/portfolio/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://naliem.github.io/portfolio/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by NalieM .",
          "url": "https://naliem.github.io/portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://naliem.github.io/portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}