<h1 id="wstęp">Wstęp</h1>

<p>Celem projektu jest porównanie skuteczności wybranych pięciu technik ML na zbiorze danych składającym się z 303 obserwacji. Jakość wyestymowanych modeli zostanie oceniona na zbiorze uczącym oraz testowym, a następnie najlepszy model zostanie zinterpretowany. Ze względu na istotną w tym projekcie interpretację wyników podjęto decyzję o wybraniu danych medycznych. Dane pacjentów pochodzą z bazy danych szpitala w Cleveland. Zestaw zawiera 14 zmiennych, w tym binarną zmianą <code class="language-plaintext highlighter-rouge">target</code>, która przyjmuje wartość 1, gdy u pacjenta występuje choroba serca lub 0, gdy nie występuje.</p>

<h2 id="dane">Dane</h2>
<p>Wykorzystany w projekcie zbiór danych Heart został opracowany na podstawie zestawu dostępnego pod adresem: https://archive.ics.uci.edu/ml/datasets/Heart+Disease. Zawiera wspomnianą wcześniej zmienną objaśnianą <code class="language-plaintext highlighter-rouge">target</code> oraz 13 zmiennych objaśniających: <br /></p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">age</code> - wiek pacjenta <br /></li>
  <li><code class="language-plaintext highlighter-rouge">sex</code> - zmienna binarna oznaczająca płeć: 1 - mężczyzna, 0-kobieta <br /></li>
  <li><code class="language-plaintext highlighter-rouge">cp</code> rodzaj bólu w klatce piersiowej związany z chorobą dusznicą bolesną w angielskiej terminologii medycznej podzielona na cztery kategorie:<br />
    <ul>
      <li>0: nie występuje <br /></li>
      <li>1: typical angina <br /></li>
      <li>2: atypical angina <br /></li>
      <li>3: non-anginal pain <br /></li>
      <li>4: asymptomatic<br /></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">trestbps</code> - ciśnienie tętnicze w mm Hg po przyjęciu do szpitala <br /></li>
  <li><code class="language-plaintext highlighter-rouge">chol</code> stężenie cholesterolu w surowicy krwi wyrażone w mg/dl <br /></li>
  <li><code class="language-plaintext highlighter-rouge">fbs</code> zmienna binarna przyjmuje wartość 1 jeżeli poziom cukru we krwi (badany na czczo) był większy niż 120 mg/dl, jeżeli nie to wartość 0 <br /></li>
  <li><code class="language-plaintext highlighter-rouge">restecg</code> zmienna jakościowa charakteryzująca wyniki elektrokardiograficzne w stanie spoczynku <br />
    <ul>
      <li>0: normalny <br /></li>
      <li>1: nieprawidłowość fali ST-T<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> <br /></li>
      <li>2: wykazujący prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa <br /></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">thalach</code> maksymalne tętno, które miał pacjent <br /></li>
  <li><code class="language-plaintext highlighter-rouge">exang</code> zmienna binarna przyjmując wartość 1 gdy wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym, w przeciwnym przypadku zmienna przyjmuje wartość 0 <br /></li>
  <li><code class="language-plaintext highlighter-rouge">oldpeak</code> wskazuje obniżenie odcinka ST<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> wywołane wysiłkiem fizycznym <br /></li>
  <li><code class="language-plaintext highlighter-rouge">slope</code> określenie szczytowej wartości nachylenia odcinka ST zmierzony podczas elektrokardiograficznego testu wysiłkowego <br />
    <ul>
      <li>0: nie występuje <br /></li>
      <li>1: wznoszący się <br /></li>
      <li>2: płaskie <br /></li>
      <li>3: opadające (downsloping) <br /></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ca</code> liczba zabarwionych głównych naczyń (0-3) w wyniku badania fluoroskopii <br /></li>
  <li><code class="language-plaintext highlighter-rouge">thal</code> zmienna jakościowa: <br />
    <ul>
      <li>0: nie występuje <br /></li>
      <li>1: 3 = normal <br /></li>
      <li>2: 6 = fixed defect <br /></li>
      <li>3: 7 = reversable defe</li>
    </ul>
  </li>
</ol>

<p>Dane nie zawierają braków oraz wartości odstających.
Poniżej zaprezentowano 6 pierwszych obserwacji pochodzących ze zbioru danych.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##   age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target
## 1  63   1  3      145  233   1       0     150     0     2.3     0  0    1      1
## 2  37   1  2      130  250   0       1     187     0     3.5     0  0    2      1
## 3  41   0  1      130  204   0       0     172     0     1.4     2  0    2      1
## 4  56   1  1      120  236   0       1     178     0     0.8     2  0    2      1
## 5  57   0  0      120  354   0       1     163     1     0.6     2  0    2      1
## 6  57   1  0      140  192   0       1     148     0     0.4     1  0    1      1
</code></pre></div></div>

<h3 id="wizualizacja-wybranych-zmiennych">Wizualizacja wybranych zmiennych</h3>

<p><strong>Zmienna objaśniana</strong></p>

<p><img src="USwR_files/figure-html/unnamed-chunk-2-1.png" width="75%" style="display: block; margin: auto;" /></p>

<p>W danych ok. 54% pacjentów zostało zdiagnozowanych pozytywnie to znaczy wykryto u nich chorobę serca (wartość 1), pozostałe 46% to przypadki, w których nie stwierdzono takiej diagnozy (wartość 0).</p>

<p><strong>Zmienna objaśniana według płci</strong></p>

<p><img src="USwR_files/figure-html/unnamed-chunk-3-1.png" width="75%" style="display: block; margin: auto;" /></p>

<p>Analizując wartości zmiennej objaśnianej <code class="language-plaintext highlighter-rouge">target</code> z podziałem na płeć można stwierdzić, że niezależnie od płci więcej przypadków w zbiorze stanowiły osoby u których zdiagnozowano chorobę serca. W próbie dominowali mężczyźni, którzy stanowili 68% rozważanych przypadków.</p>

<p><strong>Rozkład wieku pacjentów</strong></p>

<p><img src="USwR_files/figure-html/unnamed-chunk-4-1.png" width="75%" style="display: block; margin: auto;" /></p>

<p>Obserwując rozkład wieku badanych pacjentów, można ocenić, że są to osoby głównie w wieku średnim i emerytalnym.</p>

<p><strong>Wiek i płeć pacjentów względem zmiennej objaśnianej</strong></p>

<p><img src="USwR_files/figure-html/unnamed-chunk-5-1.png" width="75%" style="display: block; margin: auto;" /></p>

<p>Analiza wieku z podziałem na płeć wskazuje, że średnio kobiety były starsze w obu grupach zdiagnozowanych: pozytywnie jak i negatywnie. Trochę mniejsza różnica wieku między kobietami i mężczyznami wystąpiła wśród osób u których stwierdzono chorobę serca.</p>

<h3 id="podstawowe-statystki-opisowe">Podstawowe statystki opisowe</h3>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">summary</span><span class="p">(</span><span class="n">heart</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##       age        sex     cp         trestbps          chol       fbs    
##  Min.   :29.00   0: 96   0:143   Min.   : 94.0   Min.   :126.0   0:258  
##  1st Qu.:47.50   1:207   1: 50   1st Qu.:120.0   1st Qu.:211.0   1: 45  
##  Median :55.00           2: 87   Median :130.0   Median :240.0          
##  Mean   :54.37           3: 23   Mean   :131.6   Mean   :246.3          
##  3rd Qu.:61.00                   3rd Qu.:140.0   3rd Qu.:274.5          
##  Max.   :77.00                   Max.   :200.0   Max.   :564.0          
##  restecg    thalach      exang      oldpeak     slope   ca      thal    target 
##  0:147   Min.   : 71.0   0:204   Min.   :0.00   0: 21   0:175   0:  2   0:138  
##  1:152   1st Qu.:133.5   1: 99   1st Qu.:0.00   1:140   1: 65   1: 18   1:165  
##  2:  4   Median :153.0           Median :0.80   2:142   2: 38   2:166          
##          Mean   :149.6           Mean   :1.04           3: 20   3:117          
##          3rd Qu.:166.0           3rd Qu.:1.60           4:  5                  
##          Max.   :202.0           Max.   :6.20
</code></pre></div></div>

<p>W zbiorze danych znajduje się kilka zmiennych jakościowych, które w języku R zostały zamienione na factory. Dla zmiennych ilościowych można odczytać, że średnia wieku pacjenta to 54 lata, najmłodsza przyjęta osoba miał 29 lat, a najstarsza 77. Średnie ciśnienie tętnicze (<code class="language-plaintext highlighter-rouge">trestbps</code>) wynosiło 131, czyli przekraczało normę medyczną dla osoby dorosłej wynoszącą 120 mm Hg. Średnia wartość stężenia cholesterolu w surowicy krwi również przekracza normę dla mężczyzny 125-200 mg/d. Maksymalne tętno pacjenta wynosiło 202, gdy norma medyczna to ok. 90 uderzeń na minutę, jednak jest to zmienna wieloma różnymi czynnikami, więc raczej należy ją rozpatrywać indywidualnie dla każdego pacjenta śledząc jego historię. <code class="language-plaintext highlighter-rouge">oldpeak</code> to wskazanie obniżenia odcinka ST, którego wartość mieści się w przedziale 0 do 6,20.</p>

<h3 id="podzial-zbioru">Podzial zbioru</h3>
<p>Zbiór danych podzielony został na zbiór uczący oraz testowy w stosunku 70/30. W celu umożliwienia interpretacji wyników i ich powtarzalność ziarno generatora ustawiono na liczbę 3012.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">3012</span><span class="p">)</span><span class="w">
</span><span class="n">rand</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">303</span><span class="p">,</span><span class="w"> </span><span class="m">212</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="nb">F</span><span class="p">)</span><span class="w">
</span><span class="n">uczacy</span><span class="o">&lt;-</span><span class="w"> </span><span class="n">heart</span><span class="p">[</span><span class="n">rand</span><span class="p">,]</span><span class="w">
</span><span class="n">testowy</span><span class="o">&lt;-</span><span class="w"> </span><span class="n">heart</span><span class="p">[</span><span class="o">-</span><span class="n">rand</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div>

<h2 id="modele">Modele</h2>
<p>Wyestymowane zostaną wybrane modele ML, które zostaną zbudowane na zbiorze uczącym, proces ten będzie połączony z tuningowaniem modeli, czyli dobieraniu możliwie najlepszych wartości hierparametrów. Kryterium wyboru będzie miara dokładności. Do trenowania modelu wykorzystana zostanie metoda cross-validation z k=10. <br />
Ze względów technicznych dotyczących budowania modeli w pakiecie <code class="language-plaintext highlighter-rouge">caret</code> wartości zmiennej objaśnianej <code class="language-plaintext highlighter-rouge">target</code> zostały zmienione z 0 na ‘no’ oraz z 1 na ‘yes’.</p>

<h3 id="regresja-logistyczna">Regresja logistyczna</h3>
<p>Model regresji logistycznej nie zawiera, żadnych parametrów, które można byłoby wykorzystać do “strojenia”. Model zbudowany został dla 12 zmiennych objaśniających z pominięciem zmiennej <code class="language-plaintext highlighter-rouge">thal</code>. Zmienna ta została odrzucona ze względu na współliniowość.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
## Call:
## NULL
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.66454  -0.28812   0.09274   0.41134   2.87943  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.710365   3.613080   1.027 0.304456    
## age          0.035669   0.033207   1.074 0.282769    
## sex1        -3.141392   0.722460  -4.348 1.37e-05 ***
## cp1          1.066653   0.766703   1.391 0.164158    
## cp2          1.837301   0.625662   2.937 0.003319 ** 
## cp3          1.473897   0.870804   1.693 0.090537 .  
## trestbps    -0.023982   0.014919  -1.608 0.107941    
## chol        -0.007602   0.005515  -1.378 0.168054    
## fbs1         0.543764   0.674136   0.807 0.419891    
## restecg1     0.487174   0.520184   0.937 0.348994    
## restecg2    -1.312916   2.924249  -0.449 0.653449    
## thalach      0.021459   0.014562   1.474 0.140575    
## exang1      -1.104601   0.577601  -1.912 0.055826 .  
## oldpeak     -0.511579   0.291908  -1.753 0.079682 .  
## slope1      -1.374487   1.047819  -1.312 0.189601    
## slope2       0.126517   1.167314   0.108 0.913692    
## ca1         -2.071210   0.681284  -3.040 0.002365 ** 
## ca2         -3.531743   0.973100  -3.629 0.000284 ***
## ca3         -2.060758   0.939645  -2.193 0.028298 *  
## ca4          0.580439   1.766650   0.329 0.742493    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 292.00  on 211  degrees of freedom
## Residual deviance: 120.71  on 192  degrees of freedom
## AIC: 160.71
## 
## Number of Fisher Scoring iterations: 6
</code></pre></div></div>
<p>Jako istotne na poziomie istotności równym 0.05 model wskazał zmienne: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">sex1</code> czyli płeć, gdzie 1 oznaczało mężczyznę, <br /></li>
  <li><code class="language-plaintext highlighter-rouge">cp2</code> oznaczający 2 typ bólu klatki piersiowej w angielskiej terminologii nazywany <em>atypical angina</em>, <br /></li>
  <li><code class="language-plaintext highlighter-rouge">ca1</code>,<code class="language-plaintext highlighter-rouge">ca2</code>, <code class="language-plaintext highlighter-rouge">ca3</code> trzy z pięciu wartości wskazujących liczbę zabarwionych głównych naczyń w wyniku badania fluoroskopii, <br /></li>
  <li>zmienna <code class="language-plaintext highlighter-rouge">exang1</code> przyjmująca wartość 1 w przypadkach w których wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym nieznacznie przekracza poziom istotności 0.056.</li>
</ul>

<h4 id="jakość-modelu">Jakość modelu</h4>
<p>Jakość modelu zbadana zostanie za pomocą macierzy pomyłek oraz krzywej ROC, czyli narzędzi służących do oceny jakości klasyfikatorów. Analogiczne kroki zostaną wykonane dla kolejnych modeli.</p>

<h5 id="zbiór-uczący">Zbiór uczący</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Generalized Linear Model 
## 
## 212 samples
##  12 predictor
##   2 classes: 'no', 'yes' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 190, 192, 192, 190, 190, 190, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.8593939  0.7147427
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Cross-Validated (10 fold) Confusion Matrix 
## 
## (entries are percentual average cell counts across resamples)
##  
##           Reference
## Prediction   no  yes
##        no  37.3  6.1
##        yes  8.0 48.6
##                             
##  Accuracy (average) : 0.8585
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-9-1.png" alt="" /><!-- --></p>

<p>Na zbiorze uczącym dokładność modelu wyniosła ok. 85,9%.</p>

<h5 id="zbiór-testowy">Zbiór testowy</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction no yes
##        no  31   8
##        yes 11  41
##                                           
##                Accuracy : 0.7912          
##                  95% CI : (0.6933, 0.8694)
##     No Information Rate : 0.5385          
##     P-Value [Acc &gt; NIR] : 4.723e-07       
##                                           
##                   Kappa : 0.5778          
##                                           
##  Mcnemar's Test P-Value : 0.6464          
##                                           
##             Sensitivity : 0.8367          
##             Specificity : 0.7381          
##          Pos Pred Value : 0.7885          
##          Neg Pred Value : 0.7949          
##              Prevalence : 0.5385          
##          Detection Rate : 0.4505          
##    Detection Prevalence : 0.5714          
##       Balanced Accuracy : 0.7874          
##                                           
##        'Positive' Class : yes             
## 
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-10-1.png" alt="" /><!-- --></p>

<p>W przypadku zbioru testowego dokładność była trochę mniejsza i wyniosła 79,1%.</p>

<h3 id="k-najbliższych-sąsiadów-knn">K najbliższych sąsiadów (KNN)</h3>
<p>Metoda K najbliższych sąsiadów ma tylko jeden hiperparametr k, który określa liczbę sąsiadów. Biorąc pod uwagę wielkość zbioru uczącego podjęto decyzję o sprawdzeniu wartości od 1 do 15.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## k-Nearest Neighbors 
## 
## 212 samples
##  13 predictor
##   2 classes: 'no', 'yes' 
## 
## Pre-processing: centered (22), scaled (22) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 192, 191, 190, 191, 190, 191, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    1  0.7776840  0.5502807
##    2  0.7826623  0.5570748
##    3  0.8249134  0.6470095
##    4  0.8405844  0.6749595
##    5  0.8537662  0.7039078
##    6  0.8449351  0.6863048
##    7  0.8637879  0.7239010
##    8  0.8342641  0.6650397
##    9  0.8533333  0.7038954
##   10  0.8635498  0.7228767
##   11  0.8492424  0.6951588
##   12  0.8492424  0.6953141
##   13  0.8583117  0.7133712
##   14  0.8444805  0.6844237
##   15  0.8540043  0.7046377
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 7.
</code></pre></div></div>

<p>Jako najlepszy wybrany został model w którym hiperparemetr k przyjął wartość 7.</p>

<h4 id="jakość-modelu-1">Jakość modelu</h4>
<h5 id="zbiór-uczący-1">Zbiór uczący</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Cross-Validated (10 fold) Confusion Matrix 
## 
## (entries are percentual average cell counts across resamples)
##  
##           Reference
## Prediction   no  yes
##        no  37.3  5.7
##        yes  8.0 49.1
##                             
##  Accuracy (average) : 0.8632
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-13-1.png" alt="" /><!-- --></p>

<h5 id="zbiór-testowy-1">Zbiór testowy</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction no yes
##        no  32   9
##        yes 10  40
##                                           
##                Accuracy : 0.7912          
##                  95% CI : (0.6933, 0.8694)
##     No Information Rate : 0.5385          
##     P-Value [Acc &gt; NIR] : 4.723e-07       
##                                           
##                   Kappa : 0.5792          
##                                           
##  Mcnemar's Test P-Value : 1               
##                                           
##             Sensitivity : 0.8163          
##             Specificity : 0.7619          
##          Pos Pred Value : 0.8000          
##          Neg Pred Value : 0.7805          
##              Prevalence : 0.5385          
##          Detection Rate : 0.4396          
##    Detection Prevalence : 0.5495          
##       Balanced Accuracy : 0.7891          
##                                           
##        'Positive' Class : yes             
## 
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-14-1.png" alt="" /><!-- --></p>

<p>Podsumowując dla modelu KNN dokładność na zbiorze uczącym wynosiła 86,3%, na zbiorze testowym była trochę niższa 79,1%.</p>

<h3 id="svm">SVM</h3>
<p>Model Support Vector Machine (SVM) ma trzy hiperparametry dla każdego z nich sprawdzono 3 wartości. Na wykresie poniżej przedstawiono dokładność modeli przy różnych wartościach hiperparametrów.</p>

<p><img src="USwR_files/figure-html/unnamed-chunk-16-1.png" alt="" /><!-- --></p>

<p>Analizując wyniki można stwierdzić, że najlepszy układ hiperparametrów tj. taki w którym dokładność modelu jest największa to degree = 1, scale = 0.06 and C = 0.1.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Support Vector Machines with Polynomial Kernel 
## 
## 212 samples
##  13 predictor
##   2 classes: 'no', 'yes' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 191, 190, 191, 192, 191, 191, ... 
## Resampling results across tuning parameters:
## 
##   degree  scale  C     Accuracy   Kappa    
##   1       0.01   0.10  0.8014069  0.6106969
##   1       0.01   0.15  0.8109307  0.6279186
##   1       0.01   0.20  0.8395455  0.6776615
##   1       0.01   0.25  0.8443074  0.6870762
##   1       0.06   0.10  0.8445455  0.6865250
##   1       0.06   0.15  0.8302597  0.6574206
##   1       0.06   0.20  0.8350216  0.6668447
##   1       0.06   0.25  0.8443290  0.6861652
##   1       0.10   0.10  0.8302597  0.6569918
##   1       0.10   0.15  0.8490909  0.6949940
##   1       0.10   0.20  0.8306926  0.6574938
##   1       0.10   0.25  0.8493074  0.6960327
##   2       0.01   0.10  0.8395455  0.6776615
##   2       0.01   0.15  0.8443074  0.6870762
##   2       0.01   0.20  0.8493074  0.6959381
##   2       0.01   0.25  0.8445455  0.6865250
##   2       0.06   0.10  0.8397835  0.6761758
##   2       0.06   0.15  0.8397835  0.6761758
##   2       0.06   0.20  0.8254762  0.6470406
##   2       0.06   0.25  0.8304762  0.6574508
##   2       0.10   0.10  0.8257143  0.6482034
##   2       0.10   0.15  0.8211688  0.6391519
##   2       0.10   0.20  0.8211688  0.6394218
##   2       0.10   0.25  0.8164069  0.6290653
##   3       0.01   0.10  0.8395455  0.6776615
##   3       0.01   0.15  0.8445455  0.6871092
##   3       0.01   0.20  0.8397835  0.6761024
##   3       0.01   0.25  0.8352381  0.6669639
##   3       0.06   0.10  0.8257143  0.6468919
##   3       0.06   0.15  0.8209524  0.6371616
##   3       0.06   0.20  0.8397835  0.6747770
##   3       0.06   0.25  0.8302597  0.6559688
##   3       0.10   0.10  0.8447835  0.6849516
##   3       0.10   0.15  0.8309307  0.6579170
##   3       0.10   0.20  0.8306926  0.6583416
##   3       0.10   0.25  0.8213853  0.6390976
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were degree = 1, scale = 0.1 and C = 0.25.
</code></pre></div></div>

<h4 id="jakość-modelu-2">Jakość modelu</h4>
<h5 id="zbiór-uczący-2">Zbiór uczący</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Cross-Validated (10 fold) Confusion Matrix 
## 
## (entries are percentual average cell counts across resamples)
##  
##           Reference
## Prediction   no  yes
##        no  37.7  7.5
##        yes  7.5 47.2
##                             
##  Accuracy (average) : 0.8491
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-18-1.png" alt="" /><!-- --></p>

<h5 id="zbiór-testowy-2">Zbiór testowy</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction no yes
##        no  31   8
##        yes 11  41
##                                           
##                Accuracy : 0.7912          
##                  95% CI : (0.6933, 0.8694)
##     No Information Rate : 0.5385          
##     P-Value [Acc &gt; NIR] : 4.723e-07       
##                                           
##                   Kappa : 0.5778          
##                                           
##  Mcnemar's Test P-Value : 0.6464          
##                                           
##             Sensitivity : 0.8367          
##             Specificity : 0.7381          
##          Pos Pred Value : 0.7885          
##          Neg Pred Value : 0.7949          
##              Prevalence : 0.5385          
##          Detection Rate : 0.4505          
##    Detection Prevalence : 0.5714          
##       Balanced Accuracy : 0.7874          
##                                           
##        'Positive' Class : yes             
## 
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-19-1.png" alt="" /><!-- --></p>

<p>Dokładność modelu SVM na zbiorze uczącym to ok 84.9%, a na zbiorze testowym była dokładnie taka sama jak dla modelu KNN, czyli 79,1%.</p>

<h3 id="drzewo-klasyfikacyjne">Drzewo klasyfikacyjne</h3>

<p>Drzewo decyzyjne wykorzystywane w problemach klasyfikacyjnych nazwane jest drzewem klasyfikacyjnym. Ta metoda, ma tylko jeden hiperparametr cp, który określa wielkość drzewa. Sprawdzono sześć wartości <code class="language-plaintext highlighter-rouge">0.001, 0.01, 0.05, 0.1, 0.5, 0.9</code>. Dla najlepszego modelu przedstawiona zostanie wizualizacja drzewa klasyfikacyjnego.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## CART 
## 
## 212 samples
##  13 predictor
##   2 classes: 'no', 'yes' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 191, 191, 192, 190, 190, 190, ... 
## Resampling results across tuning parameters:
## 
##   cp     Accuracy   Kappa    
##   0.001  0.7532251  0.5024319
##   0.010  0.7532251  0.5024319
##   0.050  0.7550000  0.5076560
##   0.100  0.7695238  0.5355896
##   0.500  0.5608658  0.0384000
##   0.900  0.5472294  0.0000000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.1.
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-20-1.png" alt="" /><!-- --></p>

<h4 id="jakość-modelu-3">Jakość modelu</h4>
<h5 id="zbiór-uczący-3">Zbiór uczący</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Cross-Validated (10 fold) Confusion Matrix 
## 
## (entries are percentual average cell counts across resamples)
##  
##           Reference
## Prediction   no  yes
##        no  34.0 11.8
##        yes 11.3 42.9
##                             
##  Accuracy (average) : 0.7689
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-21-1.png" alt="" /><!-- --></p>

<h5 id="zbiór-testowy-3">Zbiór testowy</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction no yes
##        no  30  10
##        yes 12  39
##                                           
##                Accuracy : 0.7582          
##                  95% CI : (0.6572, 0.8419)
##     No Information Rate : 0.5385          
##     P-Value [Acc &gt; NIR] : 1.259e-05       
##                                           
##                   Kappa : 0.5119          
##                                           
##  Mcnemar's Test P-Value : 0.8312          
##                                           
##             Sensitivity : 0.7959          
##             Specificity : 0.7143          
##          Pos Pred Value : 0.7647          
##          Neg Pred Value : 0.7500          
##              Prevalence : 0.5385          
##          Detection Rate : 0.4286          
##    Detection Prevalence : 0.5604          
##       Balanced Accuracy : 0.7551          
##                                           
##        'Positive' Class : yes             
## 
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-22-1.png" alt="" /><!-- --></p>

<p>Model drzewa klasyfikacyjnego na zbiorze uczącym osiągnął 76,9% dokładność, natomiast na zbiorze uczącym 75,8%.</p>

<h3 id="random-forest">Random Forest</h3>

<p>Model Random Forest posiada trzy hiperparametry: mtry, splitrule (gini lub extratrees), min.node.size. W przypadku tego modelu do doboru wartości hiperparametrów wykorzystano parametr tuneLength=10 funkcji train(), który realizuje wybór parametrów w strategii Random Search. Wyniki tego poszukiwania zaprezentowano na wykresie.</p>

<p><img src="USwR_files/figure-html/unnamed-chunk-24-1.png" alt="" /><!-- --></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Random Forest 
## 
## 212 samples
##  13 predictor
##   2 classes: 'no', 'yes' 
## 
## Pre-processing: centered (22), scaled (22) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 192, 190, 191, 191, 191, 191, ... 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   Accuracy   Kappa    
##    2    gini        0.8222294  0.6400503
##    2    extratrees  0.8319913  0.6603155
##    4    gini        0.7893290  0.5751768
##    4    extratrees  0.8270130  0.6509168
##    6    gini        0.7986364  0.5946163
##    6    extratrees  0.8081602  0.6122585
##    8    gini        0.7981818  0.5945051
##    8    extratrees  0.8181602  0.6328588
##   10    gini        0.7845671  0.5671843
##   10    extratrees  0.8313420  0.6577469
##   13    gini        0.7698268  0.5372009
##   13    extratrees  0.8083983  0.6132109
##   15    gini        0.7984199  0.5947808
##   15    extratrees  0.8129437  0.6218473
##   17    gini        0.7795887  0.5564938
##   17    extratrees  0.8129437  0.6218473
##   19    gini        0.7795887  0.5564938
##   19    extratrees  0.8122727  0.6211723
##   22    gini        0.7748268  0.5469927
##   22    extratrees  0.8124892  0.6214471
## 
## Tuning parameter 'min.node.size' was held constant at a value of 1
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 2, splitrule = extratrees
##  and min.node.size = 1.
</code></pre></div></div>

<p>Hiperparametry modeli z największą wartością miary dokładności mtry = 2, splirtule = extratrees oraz min.node.size = 1.</p>

<h4 id="jakość-modelu-4">Jakość modelu</h4>
<h5 id="zbiór-uczący-4">Zbiór uczący</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Cross-Validated (10 fold) Confusion Matrix 
## 
## (entries are percentual average cell counts across resamples)
##  
##           Reference
## Prediction   no  yes
##        no  36.3  8.0
##        yes  9.0 46.7
##                             
##  Accuracy (average) : 0.8302
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-26-1.png" alt="" /><!-- --></p>

<h5 id="zbiór-testowy-4">Zbiór testowy</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction no yes
##        no  30   9
##        yes 12  40
##                                           
##                Accuracy : 0.7692          
##                  95% CI : (0.6691, 0.8511)
##     No Information Rate : 0.5385          
##     P-Value [Acc &gt; NIR] : 4.473e-06       
##                                           
##                   Kappa : 0.5333          
##                                           
##  Mcnemar's Test P-Value : 0.6625          
##                                           
##             Sensitivity : 0.8163          
##             Specificity : 0.7143          
##          Pos Pred Value : 0.7692          
##          Neg Pred Value : 0.7692          
##              Prevalence : 0.5385          
##          Detection Rate : 0.4396          
##    Detection Prevalence : 0.5714          
##       Balanced Accuracy : 0.7653          
##                                           
##        'Positive' Class : yes             
## 
</code></pre></div></div>

<p><img src="USwR_files/figure-html/unnamed-chunk-27-1.png" alt="" /><!-- --></p>

<p>Model Random Forest z wybranymi wartościami hiperparametrów osiągnął 83% dokładności na zbiorze uczącym oraz 76,9% na zbiorze uczącym.</p>

<h2 id="wyniki-i-wybór-modelu">Wyniki i wybór modelu</h2>

<p>Zestawienie miary dokładności miary dokładności dla zbioru uczącego:</p>

<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> model </th>
   <th style="text-align:right;"> accuracy_train </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> regresja logistyczna </td>
   <td style="text-align:right;"> 0.859 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> KNN </td>
   <td style="text-align:right;"> 0.863 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SVM </td>
   <td style="text-align:right;"> 0.849 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> drzewo </td>
   <td style="text-align:right;"> 0.769 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Random Forest </td>
   <td style="text-align:right;"> 0.830 </td>
  </tr>
</tbody>
</table>

<p>W przypadku zbioru testowego dodatkowo dodano miarę czułość (<em>sensitivity</em>), która wskazuje jaka część klasy pozytywnej jest pokryta pozytywnym przewidywaniem.</p>

<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> model </th>
   <th style="text-align:right;"> accuracy_test </th>
   <th style="text-align:right;"> sensivity_test </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> regresja logistyczna </td>
   <td style="text-align:right;"> 0.791 </td>
   <td style="text-align:right;"> 0.837 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> KNN </td>
   <td style="text-align:right;"> 0.791 </td>
   <td style="text-align:right;"> 0.816 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> SVM </td>
   <td style="text-align:right;"> 0.791 </td>
   <td style="text-align:right;"> 0.837 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> drzewo </td>
   <td style="text-align:right;"> 0.758 </td>
   <td style="text-align:right;"> 0.796 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Random Forest </td>
   <td style="text-align:right;"> 0.769 </td>
   <td style="text-align:right;"> 0.816 </td>
  </tr>
</tbody>
</table>

<p>Ponadto na jednym wykresie przedstawiono krzywe ROC dla wszystkich modeli.</p>

<p><img src="USwR_files/figure-html/wyniki cv-1.png" width="75%" style="display: block; margin: auto;" /></p>

<p>gdzie <br /></p>
<ul>
  <li>M1 - model regresji liniowej <br /></li>
  <li>M2 - model KNN <br /></li>
  <li>M3 - model SVM <br /></li>
  <li>M4 - model drzewo klasyfikacyjne <br /></li>
  <li>M5 - model Random Forest</li>
</ul>

<h4 id="wnioski">Wnioski</h4>

<p>Analizując otrzymane rezultaty można stwierdzić, że: <br /></p>
<ul>
  <li>najgorszym modelem na zbiorze testowym oraz uczącym był model drzewa klasyfikacyjnego (dokładność 75,8%) <br /></li>
  <li>dokładność pozostałych 4 modeli na zbiorze uczącym przekroczyła 83% <br /></li>
  <li>najlepszy na zbiorze uczącym był model KNN 86.3% <br /></li>
  <li>trzy modele: regresja logistyczna, KNN, SVM uzyskały dokładnie taką samą dokładność 79,1% na zbiorze testowym <br /></li>
  <li>dwa modele: regresja logistyczna oraz SVM miały taką samą najwyższą czułość 83,7% dla zbioru testowego  <br /></li>
  <li>dwa modele: KNN oraz Random Forest również miały taką samą czułość, która wynosiła 81.6% <br /></li>
  <li>krzywe ROC potwierdzają, że 4 modele były do siebie bardzo podobne, a jeden (drzewo klasyfikacyjne) odstawał, najbliżej idealnego modelu wydaje się być model KNN oznaczony kolorem zielonym, jednak różnice są bardzo małe <br /></li>
</ul>

<p>Do interpretacji wybrano model KNN, ponieważ na to wskazuje porównanie krzywych ROC, najwyższa dokładność w zbiorze uczącym oraz w zbiorze testowym.</p>

<h2 id="interpretacja-modelu">Interpretacja modelu</h2>
<h3 id="profile-pcp">Profile PCP</h3>

<p><strong>Profile ceteris-paribus (PCP)</strong> oceniają wpływ wybranej zmiennej objaśniającej na zmiany predykcji modelu wywołane zmianami wartości 
zmiennej przy założeniu, że inne wartości pozostają stałe. <br />
Poniżej zaprezentowano profile stworzone na podstawie modelu KNN, rozważany są dwa przypadki: <br />
1) 54 pacjent <br />
2) 54 pacjentka</p>

<h4 id="profile-pcp-54-letni-pacjent-zmienne-ilościowe">Profile PCP 54-letni pacjent zmienne ilościowe</h4>

<p><img src="USwR_files/figure-html/unnamed-chunk-30-1.png" alt="" /><!-- --></p>

<p><strong>Interpretacja</strong> <br />
Wykres profilu PCP pozwala interpretować wyniki w odniesieniu do jednej konkretniej obserwacji tutaj dla 54-letniego mężczyzny. <br />
Zmienna ilościowe: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">age</code> gdyby pacjent był starszy znacznie wzrosłaby szansa, że zostanie zdiagnozowany pozytywnie, można przypuszczać, że jeżeli pacjent nie zadba o swoje zdrowie to niedługo (rok/dwa) otrzyma diagnozę z chorobą serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">chol</code> wysokie stężenie cholesterolu w surowicy krwi bezpośrednio wiąże się z ryzykiem wystąpienia chorób serca, norma medyczna dla mężczyzn to przedział 125-200 mg/dl, pacjent nieznacznie przekracza normę, ale gdyby miał wyższe stężenie klasyfikowałby się jako pacjent z chorobą serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">oldpeak</code> wskazuje obniżenie odcinka ST wywołane wysiłkiem fizycznym, przy wartości pomiędzy 3 i 4 u pacjenta zdiagnozowano by chorobę serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">thalach</code> norma medyczna dla maksymalnego tętna wynosi 60-90 uderzeń/min, więc można zauważyć, że u badanego pacjenta norma dla dorosłego człowieka została przekroczona dwukrotnie <br /></li>
  <li><code class="language-plaintext highlighter-rouge">trestbps</code> wysoka wartość ciśnienia tętniczego oznacza pozytywną diagnozą obecności choroby serca, wartość dla rozważanego pacjenta nieznacznie przekracza normę medyczną wynoszącą 120 mm Hg, gdyby wzrosła do ok. 130 zostałby zdiagnozowany jako pacjent z chorobą serca</li>
</ul>

<h4 id="profile-pcp-54-letni-pacjent-zmienne-jakościowe">Profile PCP 54-letni pacjent zmienne jakościowe</h4>

<p><img src="USwR_files/figure-html/unnamed-chunk-31-1.png" alt="" /><!-- --></p>

<p><strong>Interpretacja</strong> <br />
Wybrane zmienne jakościowe: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">cp</code> gdyby pacjent zgłaszał dowolny typ bólu klatki piersiowej związany z dusznicą bolesną (wartość 1 lub 2) zdiagnozowano by go pozytywnie, wartości 0 i 3 wykluczają obecność tej konkretniej choroby i zmniejszają prawdopodobieństwo wystąpienia choroby serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">exang</code> gdyby u pacjenta wystąpiła wystąpiła dławica piersiowa wywołana wysiłkiem fizycznym zakwalifikowano by go jako chorego na serce, <br /></li>
  <li><code class="language-plaintext highlighter-rouge">fbs</code> jeżeli poziom cukru we krwi pacjenta był większy niż 120 mg/dl (wartość zmiennej 1) to byłby zdiagnozowany pozytywnie <br /></li>
  <li><code class="language-plaintext highlighter-rouge">restecg</code> przy wartości 1 pacjent zostałby zdiagnozowany jako osoba chora na serce, zastanawiać może wartość 2, która według modelu miałby obniżać prawdopodobieństwo pozytywnej diagnozy, co oznacza jego defekt ponieważ wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa, a wiec bezpośrednio łączy się z chorobą serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">sex</code> gdyby ten pacjent był kobietą zdiagnozowano by jako pacjenta z chorobą serca</li>
</ul>

<h4 id="profile-pcp-54-letni-pacjentka">Profile PCP 54-letni pacjentka</h4>

<p><img src="USwR_files/figure-html/unnamed-chunk-32-1.png" alt="" /><!-- --><img src="USwR_files/figure-html/unnamed-chunk-32-2.png" alt="" /><!-- --></p>

<p><strong>Interpretacja</strong> <br />
Rozważany przypadek 54-letniej kobiety wskazuje, że jej stan jest bardzo ciężki i zmiany wartości dla większości zmiennych zakładając stałość pozostałych nie wpłynęliby na zmianę diagnozy. Wyjątek stanowią: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">oldpeak</code> zmiana wartości obniżenia odcinka ST wywołane wysiłkiem fizycznym mogłaby zmniejszyć prawdopodobieństwo, ale dalej pozostałoby ono na dość wysokim poziomie, <br /></li>
  <li><code class="language-plaintext highlighter-rouge">restecg</code> przy wartości 2 prawdopodobieństwo pozytywnej diagnozy pacjentki znacznie by się zmniejszyło, co jest kolejnym dowodem na niewłaściwie działanie modelu w kontekście tej zmiennej ponieważ wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estes, a więc bezpośrednio łączy się z chorobą serca <br /></li>
  <li><code class="language-plaintext highlighter-rouge">thal</code> obniżenie tej zmiennej do wartości 1 oznaczałoby zmniejszenie prawdopodobieństwa, tutaj taka zasada działania modelu jest uzasadniona, ponieważ wartość 1 dla tej zmiennej oznacza stan normalny <br /></li>
  <li><code class="language-plaintext highlighter-rouge">cp</code> wartość 3 dla pacjentki oznaczałaby obniżenie prawdopodobieństwa diagnozy choroby serca, ponieważ oznacza ból typu non-anginal pain, czyli ból nie związany z chorobą serca <br /></li>
</ul>

<h3 id="profile-pdp">Profile PDP</h3>
<p><strong>Wykresy częściowej zależności (PDP)</strong> ich idea polega na uśrednieniu wartości wszystkich (poza jedną) zmiennych predykcyjnych i obserwacji zmiany
w odpowiedzi Y. W odróżnieniu od profili PCP dotyczą całej próby, a nie pojedynczego przypadku.</p>

<p><img src="USwR_files/figure-html/unnamed-chunk-33-1.png" alt="" /><!-- --></p>

<p><strong>Interpretacja</strong> <br />
Zgodnie z przedstawionym wykresem profili PDP dla modelu KNN można stwierdzić, że: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">age</code> wiek w niewielki sposób wpływa na prawdopodobieństwo prognozy pozytywnej <br />
-<code class="language-plaintext highlighter-rouge">chol</code> wysoka wartość cholesterolu wiąże się z większą szansą na diagnozę choroby serca <br /></li>
  <li>wraz ze wzrostem wartości <code class="language-plaintext highlighter-rouge">oldpeak</code> spada prawdopodobieństwo wystąpienia choroby serca u pacjenta <br /></li>
  <li>im większa wartość <code class="language-plaintext highlighter-rouge">thalach</code> tym większe prawdopodobieństwo pozytywnej diagnozy <br /></li>
  <li><code class="language-plaintext highlighter-rouge">trwstbps</code> ma raczej stały wpływ niezależnie od wartości w przedziale od ok. 100 do ok. 200</li>
</ul>

<h3 id="wartości-shapleya">Wartości Shapley’a</h3>
<p>Związane są z zagadnieniem znanym z teorii gier dotyczącym podziału nagrody między graczy, którzy mieli różny udział w wygranej. W ML wygrana to wartość predykcji, a graczami są zmienne, czyli atrybuty. Wartości dotyczą pojedynczych obserwacji i przedstawiają udział poszczególnych zmiennych w predykcji. Ponownie rozpatrzone zostaną przypadki 54-letniego pacjenta i pacjentki, które analizowano dla profili PCP.</p>

<h4 id="54-letni-pacjent">54-letni pacjent</h4>

<p><img src="USwR_files/figure-html/unnamed-chunk-35-1.png" alt="" /><!-- --></p>

<p>Wartości Shapley’a pozwalają ustalić, że dla badanego 54-letniego mężczyzny prawdopodobieństwo pozytywnej diagnozy zmniejszają dwie zmienne: <br /></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">sex</code> przyjmująca wartość 1, co oznacza, że fakt, że jest mężczyzną obniża prawdopodobieństwa diagnozy u niego choroby serca, <br /></li>
  <li><code class="language-plaintext highlighter-rouge">age</code> zmienna wiek obniża szansę na stwierdzenie choroby serca u tego pacjenta o 10% <br />
Pozostałe zmienne zaprezentowane na wykresie zwiększają prawdopodobieństwo stwierdzenia choroby serca u tego pacjenta: <br /></li>
  <li><code class="language-plaintext highlighter-rouge">thal</code> przyjmująca wartość 2 oznacza <em>fixed defect</em>, czyli stałą wadę i to ona w 10% wpływa na zwiększenie prawdopodobieństwa <br /></li>
  <li><code class="language-plaintext highlighter-rouge">ca</code> dwa zabarwione główne naczynia w badaniu fluoroskopii to czynnik, który o 11% zwiększa szansę na pozytywną diagnozę <br /></li>
  <li><code class="language-plaintext highlighter-rouge">slope</code> dodaje podobną wartość 7%, oznacza to, że nachylenie odcinka ST przyjmujące wartość 2 czyli ‘płaskie’ jest istotnym czynnikiem zwiększającym prawdopodobieństwa stwierdzenia choroby serca</li>
</ul>

<h4 id="54-letnia-pacjentka">54-letnia pacjentka</h4>

<p><img src="USwR_files/figure-html/unnamed-chunk-36-1.png" alt="" /><!-- --></p>

<p>Wykres otrzymany na podstawie wartości Shapley’a potwierdzają interpretację profilu PCP tej 54-letniej pacjentki, która jest “beznadziejnym przypadkiem”. W jej wynikach każda zmienna zwiększa szansę na pozytywną diagnozę. Największy wpływ 11% ma zmienna <code class="language-plaintext highlighter-rouge">ca=0</code> związana z fluoroskopią. Podobnie jak w przypadku poprzedniego pacjenta zmienna <code class="language-plaintext highlighter-rouge">thal=2</code> oznaczająca występowanie stałej wady zwiększa szanse pozytywnej diagnozy o 10%. Kolejne 7% dodają zmienne <code class="language-plaintext highlighter-rouge">slope=2</code> oraz <code class="language-plaintext highlighter-rouge">cp=0</code>. <br />
<br /></p>

<p>Analizując oba przypadki wartości dwojga pacjentów w tym samym wieku można zaobserwować znaczne podobieństwa, pomimo różnej diagnozy tj. różnego wyniku zmiennej objaśniającej dla każdego z nich.</p>

<h1 id="zakończenie">Zakończenie</h1>
<p>Cele projektu zostały zrealizowane, wyestymowano pięć modeli ML w tym dwa bazujące na drzewach decyzyjnych. Dokonano oceny jakości na podstawie miary dokładności, czułości oraz krzywych ROC. Wybrano najlepszy model i dokonano jego interpretacji przy wykorzystaniu Profili PCP, PDP oraz wartości Shapley’a. <br />
Spośród badanych modeli najlepszy dla analizowanego zbioru danych okazał się model KNN z 86% dokładnością na zbiorze uczącym oraz 79% na zbiorze uczącym. Przy okazji analizowania profili PCP i PDP odkryto prawdopodobną wadę modelu - zmienną  <code class="language-plaintext highlighter-rouge">restecg</code>, która gdy przyjmuje wartość dwa oznacza prawdopodobny lub definitywny przerost lewej komory według kryteriów Estesa, tymczasem model uznawał tą wartość jako podwód do obniżenia prawdopodobieństwa występowanie choroby serca. W celu zbadania tego problemu należałby skonsultować się z ekspertem w tej dziedzinie lub znaleźć odpowiedź w literaturze. Intuicyjnie takie zachowanie modelu można uznać za błędne. Należałby podjąć próbę zbudowania nowego modelu bez tej zmiennej i przeprowadzenie analizy porównawczej wyników.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>oryginalne wyjaśnienie medyczne dotyczące tej zmiennej (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>odcinek ST – w terminologii medycznej określenie fragmentu zapisu elektrokardiograficznego odpowiadającego początkowej fazie repolaryzacji mięśnia komór serca. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
